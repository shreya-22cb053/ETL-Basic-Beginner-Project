{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download ankitbansal06/retail-orders -f orders.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting data from zipped folder\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('orders.csv.zip') #provide file path\n",
    "zip_ref.extractall() #extract file to dir\n",
    "zip_ref.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eddb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"orders.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets go through our data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Though here there are no null values in my data, let's go through the column values to verify it\n",
    "df['Order Id'].nunique() #For ID we can check unique count instead of fetching unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ship Mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have undesirable values which we will first convert to null\n",
    "import numpy as np\n",
    "df['Ship Mode'] = df['Ship Mode'].replace(['Not Available', 'unknown'],np.nan)\n",
    "df['Ship Mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00375a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa809d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower() #we will rename the columns by replacing space with underscore and converting to lower case for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b5d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ','_')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us add new columns for sale_price and profit\n",
    "#discount = list_price - discount_percent\n",
    "#sales_price = list_price - discount\n",
    "#profit = cost_price - sales_price\n",
    "df['discount'] = df['list_price']*df['discount_percent']*0.01\n",
    "df['sales_price'] = df['list_price']-df['discount']\n",
    "df['profit'] = df['list_price'] - df['sales_price']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will remove columns that we don't need\n",
    "df.drop(columns = ['list_price','discount_percent','cost_price'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2793fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will also convert the order_date column into datetime datatype for using it in SQL\n",
    "df['order_date'] = pd.to_datetime(df['order_date'],format = \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will load this data into SQL server for which first we will create connection\n",
    "import sqlalchemy as sal\n",
    "engine = sal.create_engine('mssql://LAPTOP-VO7RFI9I/Sales_Analysis?driver=ODBC+DRIVER+17+FOR+SQL+SERVER')\n",
    "#Since I am using SSMS hence mssql\n",
    "# Here LAPTOP-VO7RFI9I is my server name\n",
    "#Sales_Analysis is my database name\n",
    "#ODBC+DRIVER+17+FOR+SQL+SERVER is my driver name which I can get from ODBC application\n",
    "conn=engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c1e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will add the dataframe in an existing database as a table\n",
    "df.to_sql('df_orders', con = conn, index = False, if_exists = 'replace')\n",
    "#df_orders will be my table name in SQL\n",
    "#We don't want index column of dataframe in our SQL table hence index = False\n",
    "#If table already exists then replace it\n",
    "#The drawback of using 'replace' is that the datatypes in SQL get assigned to the max value automatically\n",
    "#Instead we can use create the table in SQL by observing the data in Jupyter and then use if_exists = 'append' to add data to the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7224f7e",
   "metadata": {},
   "source": [
    "### Create table script\n",
    "CREATE TABLE df_orders(\n",
    "\t[order_id] int PRIMARY KEY,\n",
    "\t[order_date] date,\n",
    "\t[ship_mode] varchar(20),\n",
    "\t[segment] varchar(20),\n",
    "\t[country] varchar(20),\n",
    "\t[city] varchar(20),\n",
    "\t[state] varchar(20),\n",
    "\t[postal_code] varchar(20),\n",
    "\t[region] varchar(20),\n",
    "\t[category] varchar(20),\n",
    "\t[sub_category] varchar(20),\n",
    "\t[product_id] varchar(50),\n",
    "\t[quantity] int,\n",
    "\t[discount] decimal(7,2),\n",
    "\t[sales_price] decimal(7,2),\n",
    "\t[profit] decimal(7,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81345b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending data in existing table in SQL\n",
    "df.to_sql('df_orders', con = conn, index = False, if_exists = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb59c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
